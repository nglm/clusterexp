{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courtesy to https://github.com/deric/clustering-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pycvi.cluster import generate_all_clusterings\n",
    "from pycvi.cvi import Inertia, GapStatistic, ScoreFunction, Hartigan, Diameter, CalinskiHarabasz, Silhouette, CVIs\n",
    "from pycvi.compute_scores import compute_all_scores\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import (\n",
    "    arff_from_github, load_data_from_github, get_data_labels ,URL_ROOT,\n",
    "    write_list_datasets, UNIMODAL, UNLABELED, INVALID, UNKNOWN_K,\n",
    "    print_heads, TOO_MANY_LABELS, TOO_MANY_SAMPLES, INVALID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"artificial\"\n",
    "#DATA_SOURCE = \"real-world\"\n",
    "PATH = f\"{URL_ROOT}{DATA_SOURCE}/\"\n",
    "RES_DIR = f'../res/{DATA_SOURCE}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'{URL_ROOT}{DATA_SOURCE}.txt'\n",
    "\n",
    "all_datasets = []\n",
    "for line in urllib.request.urlopen(fname):\n",
    "    all_datasets.append(line.decode('utf-8'))\n",
    "\n",
    "print(len(all_datasets))\n",
    "all_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save list and headers of all original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fname = f'{RES_DIR}all_datasets-{DATA_SOURCE}.txt'\n",
    "# write_list_datasets(list_fname, all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_heads(fnames=all_datasets, path=PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containing multimodal and labeled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    fname for fname in all_datasets\n",
    "    if (fname not in UNIMODAL+UNLABELED)]\n",
    "print(len(filenames))\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_heads(fnames=filenames, path=PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save list of datasets that are suitable for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_for_exp = UNKNOWN_K+TOO_MANY_LABELS+TOO_MANY_SAMPLES+INVALID\n",
    "fname_exp_theory = [\n",
    "    fname for fname in all_datasets\n",
    "    if (fname not in not_for_exp)]\n",
    "print(len(fname_exp_theory))\n",
    "fname_exp_theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_theory_list_fname = f'{RES_DIR}datasets_experiments_theory-{DATA_SOURCE}.txt'\n",
    "# write_list_datasets(exp_theory_list_fname, fname_exp_theory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded = [f for f in all_datasets if f in not_for_exp]\n",
    "excluded_list_fname = f'{RES_DIR}datasets_excluded-{DATA_SOURCE}.txt'\n",
    "#write_list_datasets(excluded_list_fname, excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"zelnik1\", \"target\", \"long1\", \"xclara\"]\n",
    "\n",
    "for d in dataset_names:\n",
    "    data, labels, n_labels, meta = get_data_labels(\n",
    "        f\"{URL_ROOT}artificial/{d}.arff\", path=\"\"\n",
    "    )\n",
    "    # labels = labels.astype(float)\n",
    "    pd.DataFrame(labels).to_csv(f\"./{d}_labels.csv\", header=False, index=False)\n",
    "    pd.DataFrame(data).to_csv(f\"./{d}_data.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = arff_from_github(f'{URL_ROOT}artificial/diamond9.arff')\n",
    "df = pd.DataFrame(data)\n",
    "df.plot.scatter(\"x\", \"y\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "[t == \"int\" for t in df.dtypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_old(data, clusterings, titles):\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2, ncols=4, sharex=True, sharey=True, figsize=(15,10),\n",
    "        tight_layout=True\n",
    "    )\n",
    "    for i, ax in enumerate(axes.flat[:len(clusterings)]):\n",
    "        # Plot the clustering selected by a given score\n",
    "        for i_label, cluster in enumerate(clusterings[i]):\n",
    "            ax.scatter(data[cluster, 0], data[cluster, 1], s=0.5)\n",
    "        ax.set_title(str(titles[i]))\n",
    "    return fig, ax\n",
    "\n",
    "def plot_clusters(data, clusterings, titles):\n",
    "    # Some datasets are in 3D\n",
    "    (N, d) = data.shape\n",
    "    if d == 2:\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=2, ncols=4, sharex=True, sharey=True, figsize=(15,10),\n",
    "            tight_layout=True\n",
    "        )\n",
    "    elif d == 3:\n",
    "        fig = plt.figure(figsize=(15,10), tight_layout=True)\n",
    "    # Plot the clustering selected by a given score\n",
    "    for i in range(len(clusterings)):\n",
    "        # Plot clusters one by one\n",
    "        if d == 2:\n",
    "            ax = axes.flat[i]\n",
    "        elif d == 3:\n",
    "            ax = fig.add_subplot(2, 4, i+1, projection='3d')\n",
    "        for i_label, cluster in enumerate(clusterings[i]):\n",
    "            if d == 2:\n",
    "                ax.scatter(data[cluster, 0], data[cluster, 1], s=0.5)\n",
    "            elif d == 3:\n",
    "                ax.scatter(\n",
    "                    data[cluster, 0], data[cluster, 1], data[cluster, 2], s=0.5\n",
    "                )\n",
    "        ax.set_title(str(titles[i]))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bis = df.iloc[:, 0:-1]\n",
    "df_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_bis.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_range = [i for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_data = []\n",
    "l_n_labels = []\n",
    "l_fname = [\n",
    "    # \"diamond9.arff\",\n",
    "    \"tetra.arff\"\n",
    "    # \"xclara.arff\",\n",
    "    # \"birch-rg1.arff\",\n",
    "    # \"golfball.arff\",\n",
    "]\n",
    "for fname in l_fname:\n",
    "    if fname in UNLABELED:\n",
    "        with_labels = False\n",
    "        n_labels = 1\n",
    "    else:\n",
    "        with_labels = True\n",
    "    data, labels, meta = load_data_from_github(\n",
    "        PATH + fname, with_labels=with_labels\n",
    "    )\n",
    "    if with_labels:\n",
    "        n_labels = len(np.unique(labels))\n",
    "    l_data.append(data)\n",
    "    l_n_labels.append(n_labels)\n",
    "    print(len(data), n_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(X):\n",
    "    N = len(X)\n",
    "\n",
    "    clusterings = generate_all_clusterings(\n",
    "            X,\n",
    "            AgglomerativeClustering,\n",
    "            n_clusters_range,\n",
    "            DTW=False,\n",
    "            scaler=StandardScaler(),\n",
    "        )\n",
    "    selected_clusterings = []\n",
    "\n",
    "    for s in CVIs:\n",
    "        score = s()\n",
    "        print(\" ================ {} ================ \".format(str(score)))\n",
    "        if N > 10000 and s in [GapStatistic, Silhouette]:\n",
    "            print(\"Dataset too big for {}\".format(score))\n",
    "        else:\n",
    "            scores = compute_all_scores(\n",
    "                score,\n",
    "                X,\n",
    "                clusterings,\n",
    "                DTW=False,\n",
    "                scaler=StandardScaler(),\n",
    "            )\n",
    "\n",
    "            for k in n_clusters_range:\n",
    "                print(k, scores[0][k])\n",
    "\n",
    "            selected_k = score.select(scores)[0]\n",
    "            selected_clusterings.append(clusterings[0][selected_k])\n",
    "            print(\"Selected k {}\".format(selected_k))\n",
    "\n",
    "    fig = plot_clusters(X, selected_clusterings, CVIs)\n",
    "    fig.savefig(\"./tmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, X in enumerate(l_data):\n",
    "    print(\" ---------------- DATASET {} ---------------- \".format(l_fname[i]))\n",
    "    print(\" --------------------- True k: {} --------------------- \".format(l_n_labels[i]))\n",
    "    experiment(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nglm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
